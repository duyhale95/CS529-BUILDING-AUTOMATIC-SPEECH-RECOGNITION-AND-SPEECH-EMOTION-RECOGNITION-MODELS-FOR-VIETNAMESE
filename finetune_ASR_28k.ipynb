{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning mô hình ASR trên bộ 28k Vietnamese Voice\n",
        "\n",
        "Notebook này sử dụng dữ liệu đã được chuẩn bị ở `prepare_data_ASR_28k.ipynb` (lưu tại `./data/asr_28k`) để fine-tune mô hình `Wav2Vec2-Base-Vietnamese-250h` cho bài toán nhận dạng tiếng nói tiếng Việt.\n",
        "\n",
        "Các bước chính:\n",
        "\n",
        "1. Tải lại các split `train`, `val`, `test` từ thư mục `./data/asr_28k` bằng `load_from_disk`.\n",
        "2. Load mô hình và processor `nguyenvulebinh/wav2vec2-base-vietnamese-250h`.\n",
        "3. Tiền xử lý:\n",
        "   - Chuyển audio (`array`, `sampling_rate`) thành `input_values`.\n",
        "   - Mã hóa transcript thành `labels` phù hợp với CTC.\n",
        "4. Cấu hình `DataCollatorCTCWithPadding` để padding động cho batch.\n",
        "5. Thiết lập `TrainingArguments` và `Trainer` để huấn luyện.\n",
        "6. Huấn luyện trên tập train, đánh giá trên tập validation (metrics: WER, CER).\n",
        "7. Đánh giá cuối trên tập test.\n",
        "8. Lưu mô hình đã fine-tune vào `./models/wav2vec2-finetuned-28k-final`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu môi trường đã có các thư viện này, có thể bỏ qua cell này\n",
        "%pip install -q transformers datasets jiwer\n",
        "\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2ForCTC,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorCTCWithPadding,\n",
        ")\n",
        "from pathlib import Path\n",
        "from jiwer import wer, cer\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Kiểm tra thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Thiết bị sử dụng:\", device)\n",
        "\n",
        "# 1. Tải dữ liệu đã chuẩn bị\n",
        "print(\"\\n[1/6] Đang tải dữ liệu ASR từ ./data/asr_28k ...\")\n",
        "DATA_DIR = Path(\"./data/asr_28k\")\n",
        "train_dataset = load_from_disk(str(DATA_DIR / \"train\"))\n",
        "val_dataset = load_from_disk(str(DATA_DIR / \"val\"))\n",
        "test_dataset = load_from_disk(str(DATA_DIR / \"test\"))\n",
        "\n",
        "print(\"Số mẫu:\")\n",
        "print(\"  Train:\", len(train_dataset))\n",
        "print(\"  Val:  \", len(val_dataset))\n",
        "print(\"  Test: \", len(test_dataset))\n",
        "\n",
        "# 2. Load mô hình và processor Wav2Vec2\n",
        "print(\"\\n[2/6] Đang tải mô hình Wav2Vec2-Base-Vietnamese-250h...\")\n",
        "MODEL_ID = \"nguyenvulebinh/wav2vec2-base-vietnamese-250h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Đã tải mô hình:\", MODEL_ID)\n",
        "print(\"Kích thước vocab:\", model.config.vocab_size)\n",
        "\n",
        "# 3. Tiền xử lý dữ liệu: audio → input_values, transcript → labels\n",
        "print(\"\\n[3/6] Đang tiền xử lý dữ liệu (audio → input_values, transcript → labels)...\")\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    \"\"\"Tiền xử lý 1 batch cho Wav2Vec2 CTC.\"\"\"\n",
        "    audio = batch[\"audio\"]\n",
        "    # audio[\"array\"]: numpy array 1D, audio[\"sampling_rate\"]: tần số lấy mẫu\n",
        "    inputs = processor(\n",
        "        audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    batch[\"input_values\"] = inputs.input_values[0]\n",
        "\n",
        "    # Mã hóa transcript thành labels\n",
        "    with processor.as_target_processor():\n",
        "        labels = processor(batch[\"transcript\"]).input_ids\n",
        "    batch[\"labels\"] = labels\n",
        "    return batch\n",
        "\n",
        "# Áp dụng cho train và val (test sẽ xử lý riêng khi đánh giá nếu cần)\n",
        "train_proc = train_dataset.map(\n",
        "    prepare_batch,\n",
        "    remove_columns=train_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "val_proc = val_dataset.map(\n",
        "    prepare_batch,\n",
        "    remove_columns=val_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "print(\"Ví dụ 1 sample sau tiền xử lý:\")\n",
        "print(\"  input_values shape:\", train_proc[0][\"input_values\"].shape)\n",
        "print(\"  labels length:\", len(train_proc[0][\"labels\"]))\n",
        "\n",
        "# 4. Data collator cho CTC\n",
        "print(\"\\n[4/6] Thiết lập DataCollatorCTCWithPadding...\")\n",
        "\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
        "\n",
        "# 5. Hàm tính toán metrics (WER, CER)\n",
        "print(\"\\n[5/6] Định nghĩa hàm compute_metrics (WER, CER)...\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    # Thay -100 (label padding) bằng token pad để decode\n",
        "    label_ids = pred.label_ids\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
        "\n",
        "    wer_score = wer(label_str, pred_str)\n",
        "    cer_score = cer(label_str, pred_str)\n",
        "\n",
        "    return {\"wer\": wer_score, \"cer\": cer_score}\n",
        "\n",
        "# 6. Thiết lập TrainingArguments và Trainer\n",
        "print(\"\\n[6/6] Thiết lập TrainingArguments và Trainer...\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"./models/wav2vec2-finetuned-28k\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(OUTPUT_DIR),\n",
        "    group_by_length=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    num_train_epochs=3,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    learning_rate=3e-4,\n",
        "    warmup_steps=500,\n",
        "    logging_steps=100,\n",
        "    eval_steps=1000,\n",
        "    save_steps=1000,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_proc,\n",
        "    eval_dataset=val_proc,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Thiết lập Trainer xong. Sẵn sàng huấn luyện.\")\n",
        "print(\"\\nGọi trainer.train() trong cell tiếp theo để bắt đầu fine-tuning.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bắt đầu fine-tuning ASR\n",
        "print(\"Bắt đầu fine-tuning mô hình ASR trên bộ 28k...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nKết quả huấn luyện (tóm tắt):\")\n",
        "print(train_result)\n",
        "\n",
        "# Đánh giá trên tập validation cuối cùng\n",
        "print(\"\\nĐánh giá trên tập validation:\")\n",
        "val_metrics = trainer.evaluate()\n",
        "print(val_metrics)\n",
        "\n",
        "# Chuẩn bị test set cho đánh giá cuối\n",
        "print(\"\\nTiền xử lý test set để đánh giá cuối cùng...\")\n",
        "\n",
        "test_proc = test_dataset.map(\n",
        "    prepare_batch,\n",
        "    remove_columns=test_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "print(\"Số mẫu test:\", len(test_proc))\n",
        "\n",
        "print(\"\\nĐánh giá trên tập test:\")\n",
        "test_metrics = trainer.evaluate(test_proc)\n",
        "print(test_metrics)\n",
        "\n",
        "# Lưu mô hình fine-tuned\n",
        "FINAL_DIR = Path(\"./models/wav2vec2-finetuned-28k-final\")\n",
        "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nĐang lưu mô hình đã fine-tune vào:\", FINAL_DIR.resolve())\n",
        "trainer.save_model(str(FINAL_DIR))\n",
        "processor.save_pretrained(str(FINAL_DIR))\n",
        "\n",
        "print(\"Hoàn thành fine-tuning ASR và lưu mô hình.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
