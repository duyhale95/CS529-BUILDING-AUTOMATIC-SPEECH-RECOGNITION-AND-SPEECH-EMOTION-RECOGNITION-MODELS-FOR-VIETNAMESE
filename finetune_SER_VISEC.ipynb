{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning mô hình SER trên bộ ViSEC\n",
        "\n",
        "Notebook này sử dụng dữ liệu đã được chuẩn bị ở `prepare_data_SER_VISEC.ipynb` (lưu tại `./data/ser_visec`) để fine-tune mô hình `superb/hubert-large-superb-er` cho bài toán nhận diện cảm xúc trong giọng nói tiếng Việt.\n",
        "\n",
        "Các bước chính:\n",
        "\n",
        "1. Tải lại các split `train`, `val`, `test` từ thư mục `./data/ser_visec` bằng `load_from_disk`.\n",
        "2. Load mô hình và feature extractor `superb/hubert-large-superb-er`.\n",
        "3. Cấu hình lại đầu ra của mô hình với 3 lớp cảm xúc: `positive`, `negative`, `neutral`.\n",
        "4. Tiền xử lý:\n",
        "   - Chuyển audio (`array`, `sampling_rate`) thành `input_values`, `attention_mask`.\n",
        "   - Mã hóa nhãn cảm xúc thành các chỉ số 0, 1, 2.\n",
        "5. Thiết lập `DataCollatorWithPadding` cho batch.\n",
        "6. Thiết lập `TrainingArguments` và `Trainer` để huấn luyện.\n",
        "7. Huấn luyện trên tập train, đánh giá trên tập validation (metrics: Accuracy, F1-score).\n",
        "8. Đánh giá cuối trên tập test, in thêm Confusion Matrix / Classification Report nếu cần.\n",
        "9. Lưu mô hình đã fine-tune vào `./models/hubert-ser-finetuned-visec-final`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Nếu môi trường đã có các thư viện này, có thể bỏ qua cell này\u001b[39;00m\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall -q transformers datasets scikit-learn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_from_disk\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     AutoModelForAudioClassification,\n\u001b[0;32m      8\u001b[0m     AutoFeatureExtractor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     DataCollatorWithPadding,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.4.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Column, Dataset\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     CommitInfo,\n\u001b[0;32m     65\u001b[0m     CommitOperationAdd,\n\u001b[0;32m     66\u001b[0m     CommitOperationDelete,\n\u001b[0;32m     67\u001b[0m     DatasetCard,\n\u001b[0;32m     68\u001b[0m     DatasetCardData,\n\u001b[0;32m     69\u001b[0m     HfApi,\n\u001b[0;32m     70\u001b[0m )\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RepoFile\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfHubHTTPError, RepositoryNotFoundError\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\__init__.py:1044\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1042\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1044\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError importing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubmod_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\hf_api.py:56\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_commit_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CommitOperation,\n\u001b[0;32m     58\u001b[0m     CommitOperationAdd,\n\u001b[0;32m     59\u001b[0m     CommitOperationCopy,\n\u001b[0;32m     60\u001b[0m     CommitOperationDelete,\n\u001b[0;32m     61\u001b[0m     _fetch_files_to_copy,\n\u001b[0;32m     62\u001b[0m     _fetch_upload_modes,\n\u001b[0;32m     63\u001b[0m     _prepare_commit_payload,\n\u001b[0;32m     64\u001b[0m     _upload_files,\n\u001b[0;32m     65\u001b[0m     _warn_on_overwriting_operations,\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inference_endpoints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEndpoint, InferenceEndpointType\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_jobs_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JobInfo, JobSpec, ScheduledJobInfo, _create_job_spec\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\_commit_api.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntryNotFoundError, HfHubHTTPError, XetAuthorizationError, XetRefreshTokenError\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_url\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadInfo, lfs_upload, post_lfs_batch_info\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     FORBIDDEN_FOLDERS,\n\u001b[0;32m     24\u001b[0m     XetTokenType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     34\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:22\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     __version__,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     constants,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_local_folder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_local_download_paths, read_download_metadata, write_download_metadata\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     HUGGINGFACE_CO_URL_TEMPLATE,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     HUGGINGFACE_HUB_CACHE,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     29\u001b[0m     FileMetadataError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     35\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\_local_folder.py:61\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WeakFileLock\n\u001b[0;32m     64\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLocalDownloadFilePaths\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\__init__.py:104\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_paths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_IGNORE_PATTERNS, FORBIDDEN_FOLDERS, filter_repo_objects\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_runtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     65\u001b[0m     dump_environment_info,\n\u001b[0;32m     66\u001b[0m     get_aiohttp_version,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     is_torch_available,\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_safetensors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SafetensorsFileMetadata, SafetensorsRepoMetadata, TensorInfo\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subprocess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_output, run_interactive_subprocess, run_subprocess\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_telemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m send_telemetry\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu môi trường đã có các thư viện này, có thể bỏ qua cell này\n",
        "%pip install -q transformers datasets scikit-learn torch torchaudio\n",
        "\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    AutoModelForAudioClassification,\n",
        "    AutoFeatureExtractor,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Thiết bị sử dụng:\", device)\n",
        "\n",
        "# 1. Tải dữ liệu SER đã chuẩn bị\n",
        "print(\"\\n[1/6] Đang tải dữ liệu SER từ ./data/ser_visec ...\")\n",
        "DATA_DIR = Path(\"./data/ser_visec\")\n",
        "train_dataset = load_from_disk(str(DATA_DIR / \"train\"))\n",
        "val_dataset = load_from_disk(str(DATA_DIR / \"val\"))\n",
        "test_dataset = load_from_disk(str(DATA_DIR / \"test\"))\n",
        "\n",
        "print(\"Số mẫu:\")\n",
        "print(\"  Train:\", len(train_dataset))\n",
        "print(\"  Val:  \", len(val_dataset))\n",
        "print(\"  Test: \", len(test_dataset))\n",
        "\n",
        "# 2. Load mô hình và feature extractor HuBERT\n",
        "print(\"\\n[2/6] Đang tải mô hình HuBERT cho SER...\")\n",
        "SER_MODEL_ID = \"superb/hubert-large-superb-er\"\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(SER_MODEL_ID)\n",
        "\n",
        "# Cấu hình lại đầu ra với 3 lớp\n",
        "label2id = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    SER_MODEL_ID,\n",
        "    num_labels=3,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print(\"Đã tải mô hình:\", SER_MODEL_ID)\n",
        "print(\"Số lớp cảm xúc:\", model.config.num_labels)\n",
        "\n",
        "# 3. Tiền xử lý dữ liệu: audio → input_values, labels\n",
        "print(\"\\n[3/6] Đang tiền xử lý dữ liệu SER...\")\n",
        "\n",
        "def prepare_ser_batch(batch):\n",
        "    \"\"\"Tiền xử lý 1 sample cho SER HuBERT.\"\"\"\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    inputs = feature_extractor(\n",
        "        audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    batch[\"input_values\"] = inputs[\"input_values\"][0]\n",
        "    # Một số feature_extractor không trả về attention_mask; kiểm tra trước\n",
        "    if \"attention_mask\" in inputs:\n",
        "        batch[\"attention_mask\"] = inputs[\"attention_mask\"][0]\n",
        "\n",
        "    # Mã hóa nhãn cảm xúc\n",
        "    batch[\"labels\"] = label2id[str(batch[\"emotion\"]).lower().strip()]\n",
        "    return batch\n",
        "\n",
        "train_proc = train_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=train_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "val_proc = val_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=val_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "test_proc = test_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=test_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "print(\"Ví dụ 1 sample sau tiền xử lý:\")\n",
        "print(\"  input_values shape:\", train_proc[0][\"input_values\"].shape)\n",
        "print(\"  label:\", train_proc[0][\"labels\"])\n",
        "\n",
        "# 4. Data collator\n",
        "print(\"\\n[4/6] Thiết lập DataCollatorWithPadding...\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=feature_extractor,\n",
        "    padding=True,\n",
        ")\n",
        "\n",
        "# 5. Hàm metrics: Accuracy, F1-score (weighted)\n",
        "print(\"\\n[5/6] Định nghĩa hàm compute_metrics (Accuracy, F1-score)...\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# 6. Thiết lập TrainingArguments và Trainer\n",
        "print(\"\\n[6/6] Thiết lập TrainingArguments và Trainer...\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"./models/hubert-ser-finetuned-visec\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(OUTPUT_DIR),\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_proc,\n",
        "    eval_dataset=val_proc,\n",
        "    tokenizer=feature_extractor,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Thiết lập Trainer xong. Sẵn sàng huấn luyện.\")\n",
        "print(\"\\nGọi trainer.train() trong cell tiếp theo để bắt đầu fine-tuning.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bắt đầu fine-tuning SER\n",
        "print(\"Bắt đầu fine-tuning mô hình SER trên bộ ViSEC...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nKết quả huấn luyện (tóm tắt):\")\n",
        "print(train_result)\n",
        "\n",
        "# Đánh giá trên tập validation cuối cùng\n",
        "print(\"\\nĐánh giá trên tập validation:\")\n",
        "val_metrics = trainer.evaluate()\n",
        "print(val_metrics)\n",
        "\n",
        "# Đánh giá chi tiết trên tập test\n",
        "print(\"\\nĐánh giá chi tiết trên tập test...\")\n",
        "\n",
        "test_logits = trainer.predict(test_proc)\n",
        "logits = test_logits.predictions\n",
        "labels = test_logits.label_ids\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "print(\"Metrics trên test set:\")\n",
        "print(\"  Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"  F1 (weighted):\", f1_score(labels, preds, average=\"weighted\"))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(labels, preds))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds, target_names=[id2label[i] for i in range(3)]))\n",
        "\n",
        "# Lưu mô hình fine-tuned\n",
        "FINAL_DIR = Path(\"./models/hubert-ser-finetuned-visec-final\")\n",
        "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nĐang lưu mô hình đã fine-tune vào:\", FINAL_DIR.resolve())\n",
        "trainer.save_model(str(FINAL_DIR))\n",
        "feature_extractor.save_pretrained(str(FINAL_DIR))\n",
        "\n",
        "print(\"Hoàn thành fine-tuning SER và lưu mô hình.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
