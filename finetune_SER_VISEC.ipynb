{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning mô hình SER trên bộ ViSEC\n",
        "\n",
        "Notebook này sử dụng dữ liệu đã được chuẩn bị ở `prepare_data_SER_VISEC.ipynb` (lưu tại `./data/ser_visec`) để fine-tune mô hình `superb/hubert-large-superb-er` cho bài toán nhận diện cảm xúc trong giọng nói tiếng Việt.\n",
        "\n",
        "Các bước chính:\n",
        "\n",
        "1. Tải lại các split `train`, `val`, `test` từ thư mục `./data/ser_visec` bằng `load_from_disk`.\n",
        "2. Load mô hình và feature extractor `superb/hubert-large-superb-er`.\n",
        "3. Cấu hình lại đầu ra của mô hình với 3 lớp cảm xúc: `positive`, `negative`, `neutral`.\n",
        "4. Tiền xử lý:\n",
        "   - Chuyển audio (`array`, `sampling_rate`) thành `input_values`, `attention_mask`.\n",
        "   - Mã hóa nhãn cảm xúc thành các chỉ số 0, 1, 2.\n",
        "5. Thiết lập `DataCollatorWithPadding` cho batch.\n",
        "6. Thiết lập `TrainingArguments` và `Trainer` để huấn luyện.\n",
        "7. Huấn luyện trên tập train, đánh giá trên tập validation (metrics: Accuracy, F1-score).\n",
        "8. Đánh giá cuối trên tập test, in thêm Confusion Matrix / Classification Report nếu cần.\n",
        "9. Lưu mô hình đã fine-tune vào `./models/hubert-ser-finetuned-visec-final`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu môi trường đã có các thư viện này, có thể bỏ qua cell này\n",
        "%pip install -q transformers datasets scikit-learn\n",
        "\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    AutoModelForAudioClassification,\n",
        "    AutoFeatureExtractor,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Thiết bị sử dụng:\", device)\n",
        "\n",
        "# 1. Tải dữ liệu SER đã chuẩn bị\n",
        "print(\"\\n[1/6] Đang tải dữ liệu SER từ ./data/ser_visec ...\")\n",
        "DATA_DIR = Path(\"./data/ser_visec\")\n",
        "train_dataset = load_from_disk(str(DATA_DIR / \"train\"))\n",
        "val_dataset = load_from_disk(str(DATA_DIR / \"val\"))\n",
        "test_dataset = load_from_disk(str(DATA_DIR / \"test\"))\n",
        "\n",
        "print(\"Số mẫu:\")\n",
        "print(\"  Train:\", len(train_dataset))\n",
        "print(\"  Val:  \", len(val_dataset))\n",
        "print(\"  Test: \", len(test_dataset))\n",
        "\n",
        "# 2. Load mô hình và feature extractor HuBERT\n",
        "print(\"\\n[2/6] Đang tải mô hình HuBERT cho SER...\")\n",
        "SER_MODEL_ID = \"superb/hubert-large-superb-er\"\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(SER_MODEL_ID)\n",
        "\n",
        "# Cấu hình lại đầu ra với 3 lớp\n",
        "label2id = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    SER_MODEL_ID,\n",
        "    num_labels=3,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print(\"Đã tải mô hình:\", SER_MODEL_ID)\n",
        "print(\"Số lớp cảm xúc:\", model.config.num_labels)\n",
        "\n",
        "# 3. Tiền xử lý dữ liệu: audio → input_values, labels\n",
        "print(\"\\n[3/6] Đang tiền xử lý dữ liệu SER...\")\n",
        "\n",
        "def prepare_ser_batch(batch):\n",
        "    \"\"\"Tiền xử lý 1 sample cho SER HuBERT.\"\"\"\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    inputs = feature_extractor(\n",
        "        audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    batch[\"input_values\"] = inputs[\"input_values\"][0]\n",
        "    # Một số feature_extractor không trả về attention_mask; kiểm tra trước\n",
        "    if \"attention_mask\" in inputs:\n",
        "        batch[\"attention_mask\"] = inputs[\"attention_mask\"][0]\n",
        "\n",
        "    # Mã hóa nhãn cảm xúc\n",
        "    batch[\"labels\"] = label2id[str(batch[\"emotion\"]).lower().strip()]\n",
        "    return batch\n",
        "\n",
        "train_proc = train_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=train_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "val_proc = val_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=val_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "test_proc = test_dataset.map(\n",
        "    prepare_ser_batch,\n",
        "    remove_columns=test_dataset.column_names,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "print(\"Ví dụ 1 sample sau tiền xử lý:\")\n",
        "print(\"  input_values shape:\", train_proc[0][\"input_values\"].shape)\n",
        "print(\"  label:\", train_proc[0][\"labels\"])\n",
        "\n",
        "# 4. Data collator\n",
        "print(\"\\n[4/6] Thiết lập DataCollatorWithPadding...\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=feature_extractor,\n",
        "    padding=True,\n",
        ")\n",
        "\n",
        "# 5. Hàm metrics: Accuracy, F1-score (weighted)\n",
        "print(\"\\n[5/6] Định nghĩa hàm compute_metrics (Accuracy, F1-score)...\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# 6. Thiết lập TrainingArguments và Trainer\n",
        "print(\"\\n[6/6] Thiết lập TrainingArguments và Trainer...\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"./models/hubert-ser-finetuned-visec\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(OUTPUT_DIR),\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_proc,\n",
        "    eval_dataset=val_proc,\n",
        "    tokenizer=feature_extractor,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Thiết lập Trainer xong. Sẵn sàng huấn luyện.\")\n",
        "print(\"\\nGọi trainer.train() trong cell tiếp theo để bắt đầu fine-tuning.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bắt đầu fine-tuning SER\n",
        "print(\"Bắt đầu fine-tuning mô hình SER trên bộ ViSEC...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nKết quả huấn luyện (tóm tắt):\")\n",
        "print(train_result)\n",
        "\n",
        "# Đánh giá trên tập validation cuối cùng\n",
        "print(\"\\nĐánh giá trên tập validation:\")\n",
        "val_metrics = trainer.evaluate()\n",
        "print(val_metrics)\n",
        "\n",
        "# Đánh giá chi tiết trên tập test\n",
        "print(\"\\nĐánh giá chi tiết trên tập test...\")\n",
        "\n",
        "test_logits = trainer.predict(test_proc)\n",
        "logits = test_logits.predictions\n",
        "labels = test_logits.label_ids\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "print(\"Metrics trên test set:\")\n",
        "print(\"  Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"  F1 (weighted):\", f1_score(labels, preds, average=\"weighted\"))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(labels, preds))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds, target_names=[id2label[i] for i in range(3)]))\n",
        "\n",
        "# Lưu mô hình fine-tuned\n",
        "FINAL_DIR = Path(\"./models/hubert-ser-finetuned-visec-final\")\n",
        "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nĐang lưu mô hình đã fine-tune vào:\", FINAL_DIR.resolve())\n",
        "trainer.save_model(str(FINAL_DIR))\n",
        "feature_extractor.save_pretrained(str(FINAL_DIR))\n",
        "\n",
        "print(\"Hoàn thành fine-tuning SER và lưu mô hình.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
