{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chuẩn bị dữ liệu ASR với bộ 28k Vietnamese Voice\n",
        "\n",
        "Notebook này thực hiện các bước:\n",
        "\n",
        "1. Tải bộ dữ liệu `natmin322/28k_vietnamese_voice_augmented_of_VigBigData` từ Hugging Face.\n",
        "2. Chuẩn hóa cấu trúc dữ liệu cho bài toán ASR:\n",
        "   - Chuẩn audio về sampling rate 16 kHz, mono (dùng cột `audio` của Hugging Face Datasets).\n",
        "   - Chuẩn hóa trường transcript (cột `sentence`).\n",
        "3. Gộp các split train (`train_1` → `train_5`) thành một tập train lớn.\n",
        "4. Chia lại thành `train` và `validation` (90% / 10%).\n",
        "5. Giữ nguyên split `test` gốc của dataset.\n",
        "6. Lưu lại các split dưới dạng Hugging Face Dataset bằng `save_to_disk` để dùng cho huấn luyện ASR sau này.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Nếu đã có rồi thì có thể bỏ qua cell này\u001b[39;00m\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall -q datasets soundfile librosa tqdm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset, concatenate_datasets, Audio\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 1.1.5 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu đã có rồi thì có thể bỏ qua cell này\n",
        "%pip install -q datasets soundfile librosa tqdm torchcodec\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets, Audio\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Thư mục lưu dataset đã xử lý\n",
        "OUTPUT_DIR = Path(\"./data/asr_28k\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Thư mục lưu dữ liệu:\", OUTPUT_DIR.resolve())\n",
        "a\n",
        "# 1. Tải dataset 28k từ Hugging Face\n",
        "print(\"\\n[1/4] Đang tải dataset 28k Vietnamese Voice từ Hugging Face...\")\n",
        "vig_dataset = load_dataset(\"natmin322/28k_vietnamese_voice_augmented_of_VigBigData\")\n",
        "print(\"Các splits có sẵn:\", list(vig_dataset.keys()))\n",
        "\n",
        "# 2. Gộp các split train_1 → train_5\n",
        "print(\"\\n[2/4] Đang gộp các split train_1 → train_5...\")\n",
        "train_splits = [f\"train_{i}\" for i in range(1, 6)]\n",
        "train_datasets = [vig_dataset[split] for split in train_splits]\n",
        "\n",
        "vig_train_all = concatenate_datasets(train_datasets)\n",
        "vig_test = vig_dataset[\"test\"]\n",
        "\n",
        "print(f\"Số mẫu train (gộp): {len(vig_train_all)}\")\n",
        "print(f\"Số mẫu test: {len(vig_test)}\")\n",
        "\n",
        "# 3. Chuẩn hóa cấu trúc cho ASR: audio (16 kHz), transcript (lowercase, strip)\n",
        "print(\"\\n[3/4] Đang chuẩn hóa cấu trúc dữ liệu cho ASR...\")\n",
        "\n",
        "def prepare_asr_example(example):\n",
        "    \"\"\"Chuẩn hóa 1 sample cho bài toán ASR.\"\"\"\n",
        "    # Cột `audio` của Hugging Face đã chứa array và sampling_rate\n",
        "    audio = example[\"audio\"]\n",
        "    transcript = example[\"sentence\"]\n",
        "\n",
        "    return {\n",
        "        \"audio\": audio,\n",
        "        \"transcript\": str(transcript).lower().strip(),\n",
        "        \"duration\": float(audio[\"duration\"]),\n",
        "    }\n",
        "\n",
        "# Áp dụng cho train và test\n",
        "vig_train_processed = vig_train_all.map(\n",
        "    prepare_asr_example,\n",
        "    remove_columns=[col for col in vig_train_all.column_names if col not in [\"audio\", \"sentence\"]],\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "vig_test_processed = vig_test.map(\n",
        "    prepare_asr_example,\n",
        "    remove_columns=[col for col in vig_test.column_names if col not in [\"audio\", \"sentence\"]],\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "# Đảm bảo cột audio được cast về Audio với sampling_rate = 16 kHz\n",
        "vig_train_processed = vig_train_processed.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "vig_test_processed = vig_test_processed.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"Hoàn tất chuẩn hóa. Ví dụ 1 sample train:\")\n",
        "print({k: vig_train_processed[0][k] for k in [\"transcript\", \"duration\"]})\n",
        "\n",
        "# 4. Chia train thành train/validation (90% / 10%)\n",
        "print(\"\\n[4/4] Đang chia train thành train/validation (90% / 10%)...\")\n",
        "\n",
        "split_dict = vig_train_processed.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = split_dict[\"train\"]\n",
        "val_dataset = split_dict[\"test\"]\n",
        "\n",
        "total_train = len(train_dataset)\n",
        "total_val = len(val_dataset)\n",
        "total_test = len(vig_test_processed)\n",
        "\n",
        "print(f\"Số mẫu train: {total_train}\")\n",
        "print(f\"Số mẫu val:   {total_val}\")\n",
        "print(f\"Số mẫu test:  {total_test}\")\n",
        "\n",
        "# 5. Lưu dataset đã xử lý xuống đĩa bằng save_to_disk\n",
        "print(\"\\nĐang lưu các split đã xử lý xuống đĩa...\")\n",
        "\n",
        "train_path = OUTPUT_DIR / \"train\"\n",
        "val_path = OUTPUT_DIR / \"val\"\n",
        "test_path = OUTPUT_DIR / \"test\"\n",
        "\n",
        "train_dataset.save_to_disk(str(train_path))\n",
        "val_dataset.save_to_disk(str(val_path))\n",
        "vig_test_processed.save_to_disk(str(test_path))\n",
        "\n",
        "print(\"Đã lưu:\")\n",
        "print(\"  - Train:\", train_path.resolve())\n",
        "print(\"  - Val:  \", val_path.resolve())\n",
        "print(\"  - Test: \", test_path.resolve())\n",
        "\n",
        "# 6. Lưu thống kê cơ bản vào file JSON\n",
        "print(\"\\nĐang ghi thống kê dữ liệu vào stats.json...\")\n",
        "\n",
        "train_transcripts = [ex[\"transcript\"] for ex in train_dataset]\n",
        "train_lengths = [len(t) for t in train_transcripts]\n",
        "train_durations = [ex[\"duration\"] for ex in train_dataset]\n",
        "\n",
        "stats = {\n",
        "    \"train_samples\": total_train,\n",
        "    \"val_samples\": total_val,\n",
        "    \"test_samples\": total_test,\n",
        "    \"avg_transcript_length\": float(sum(train_lengths) / len(train_lengths)),\n",
        "    \"min_transcript_length\": int(min(train_lengths)),\n",
        "    \"max_transcript_length\": int(max(train_lengths)),\n",
        "    \"avg_duration\": float(sum(train_durations) / len(train_durations)),\n",
        "    \"min_duration\": float(min(train_durations)),\n",
        "    \"max_duration\": float(max(train_durations)),\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Hoàn thành chuẩn bị dữ liệu ASR cho bộ 28k Vietnamese Voice.\")\n",
        "print(\"Thống kê chính:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phiên bản đầy đủ tiền xử lý ASR (28k) theo các bước trong thuyết minh\n",
        "\n",
        "Phần dưới đây hiện thực pipeline tiền xử lý đầy đủ cho bộ `natmin322/28k_vietnamese_voice_augmented_of_VigBigData` dùng cho ASR:\n",
        "\n",
        "1. **Chuẩn hóa định dạng**: audio về 16 kHz, mono, chuẩn hóa biên độ (tránh clipping).\n",
        "2. **Lọc nhiễu, cắt im lặng, loại bỏ mẫu lỗi**: loại bỏ các mẫu quá ngắn/dài, nhiều im lặng, clipping, RMS quá thấp.\n",
        "3. **(Không cân bằng nhãn)**: bộ 28k không có nhãn cảm xúc, nên bước cân bằng nhãn không áp dụng cho ASR.\n",
        "4. **Tăng cường dữ liệu (data augmentation)**: áp dụng cho tập train (time-stretch, pitch-shift, thêm noise, thay đổi volume) để tăng đa dạng tín hiệu.\n",
        "5. **Chia dữ liệu**:\n",
        "   - Tập train/val được tạo từ các split `train_1` → `train_5` sau khi lọc và augment.\n",
        "   - Tập test giữ nguyên từ split `test` của dataset (chỉ áp dụng chuẩn hóa + lọc nhiễu, không augment).\n",
        "6. **Lưu kết quả**: lưu thành Hugging Face Dataset tại `./data/asr_28k/{train,val,test}` và ghi thống kê `stats.json`.\n",
        "\n",
        "Sau khi chạy xong cell code bên dưới, bạn có thể sử dụng trực tiếp các thư mục này trong notebook `finetune_ASR_28k.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PIPELINE TIỀN XỬ LÝ ĐẦY ĐỦ CHO ASR (28K DATASET)\n",
        "\n",
        "%pip install -q datasets librosa soundfile tqdm noisereduce scikit-learn torchcodec\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "\n",
        "from scipy import signal\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from datasets import load_dataset, Dataset, Audio\n",
        "import json\n",
        "import random\n",
        "import librosa.effects as effects\n",
        "\n",
        "# ==========================\n",
        "# 1. CHUẨN HÓA + TẠO normalized_data_28k\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"1. CHUẨN HÓA ĐỊNH DẠNG CHO 28K DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "vig_dataset = load_dataset(\"natmin322/28k_vietnamese_voice_augmented_of_VigBigData\")\n",
        "print(\"Các splits có sẵn:\", list(vig_dataset.keys()))\n",
        "\n",
        "normalized_data_28k = []\n",
        "\n",
        "TARGET_SR = 16000\n",
        "\n",
        "for split_name in [\"train_1\", \"train_2\", \"train_3\", \"train_4\", \"train_5\", \"test\"]:\n",
        "    print(f\"\\nProcessing split: {split_name} ...\")\n",
        "    split_data = vig_dataset[split_name]\n",
        "\n",
        "    for idx, ex in enumerate(tqdm(split_data, desc=split_name)):\n",
        "        audio = ex[\"audio\"]  # {'array', 'sampling_rate', 'path', ...}\n",
        "        y = audio[\"array\"]\n",
        "        sr = audio[\"sampling_rate\"]\n",
        "\n",
        "        # Đảm bảo mono\n",
        "        if y.ndim > 1:\n",
        "            y = librosa.to_mono(y)\n",
        "\n",
        "        # Resample về 16 kHz nếu cần\n",
        "        if sr != TARGET_SR:\n",
        "            y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)\n",
        "            sr = TARGET_SR\n",
        "\n",
        "        # Normalize amplitude (tránh clipping)\n",
        "        max_val = np.abs(y).max()\n",
        "        if max_val > 0.95:\n",
        "            y = y / max_val * 0.95\n",
        "\n",
        "        normalized_data_28k.append(\n",
        "            {\n",
        "                \"audio_array\": y,\n",
        "                \"sampling_rate\": sr,\n",
        "                \"transcript\": str(ex[\"sentence\"]).lower().strip(),\n",
        "                \"duration\": len(y) / sr,\n",
        "                \"split\": split_name,\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(f\"\\nĐã chuẩn hóa {len(normalized_data_28k)} samples từ 28k dataset.\")\n",
        "\n",
        "# ==========================\n",
        "# 2. LỌC NHIỄU, CẮT IM LẶNG, LOẠI MẪU LỖI\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"2. LỌC NHIỄU, CẮT IM LẶNG, LOẠI MẪU LỖI CHO ASR\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def detect_silence(audio, sr, threshold_db=-40):\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    rms_db = librosa.power_to_db(rms**2)\n",
        "    silence_mask = rms_db < threshold_db\n",
        "    silence_ratio = np.sum(silence_mask) / len(silence_mask)\n",
        "    return silence_ratio\n",
        "\n",
        "\n",
        "def remove_silence(audio, sr, frame_length=2048, hop_length=512, top_db=20):\n",
        "    audio_trimmed, _ = librosa.effects.trim(\n",
        "        audio,\n",
        "        top_db=top_db,\n",
        "        frame_length=frame_length,\n",
        "        hop_length=hop_length,\n",
        "    )\n",
        "    return audio_trimmed\n",
        "\n",
        "\n",
        "def reduce_noise(audio, sr, stationary=False):\n",
        "    try:\n",
        "        audio_clean = nr.reduce_noise(\n",
        "            y=audio,\n",
        "            sr=sr,\n",
        "            stationary=stationary,\n",
        "        )\n",
        "        return audio_clean\n",
        "    except Exception:\n",
        "        b, a = signal.butter(3, 80, \"hp\", fs=sr)\n",
        "        audio_clean = signal.filtfilt(b, a, audio)\n",
        "        return audio_clean\n",
        "\n",
        "\n",
        "def check_audio_quality(audio, sr, min_duration=0.5, max_duration=30):\n",
        "    duration = len(audio) / sr\n",
        "\n",
        "    if duration < min_duration or duration > max_duration:\n",
        "        return False, f\"Invalid duration: {duration:.2f}s\"\n",
        "\n",
        "    silence_ratio = detect_silence(audio, sr)\n",
        "    if silence_ratio > 0.8:\n",
        "        return False, f\"Too much silence: {silence_ratio:.2%}\"\n",
        "\n",
        "    max_val = np.abs(audio).max()\n",
        "    if max_val > 0.99:\n",
        "        return False, f\"Audio clipping detected: {max_val:.3f}\"\n",
        "\n",
        "    rms = librosa.feature.rms(y=audio)[0].mean()\n",
        "    if rms < 0.005:\n",
        "        return False, f\"RMS too low: {rms:.4f}\"\n",
        "\n",
        "    return True, \"OK\"\n",
        "\n",
        "\n",
        "def preprocess_audio_pipeline(audio_array, sr, reduce_noise_flag=True):\n",
        "    audio_processed = remove_silence(audio_array, sr)\n",
        "\n",
        "    if reduce_noise_flag:\n",
        "        audio_processed = reduce_noise(audio_processed, sr)\n",
        "\n",
        "    max_val = np.abs(audio_processed).max()\n",
        "    if max_val > 0:\n",
        "        audio_processed = audio_processed / max_val * 0.95\n",
        "\n",
        "    return audio_processed\n",
        "\n",
        "\n",
        "cleaned_data_28k = []\n",
        "removed_samples_28k = []\n",
        "\n",
        "for idx, sample in enumerate(tqdm(normalized_data_28k, desc=\"Cleaning 28k\")):\n",
        "    audio_array = sample[\"audio_array\"]\n",
        "    sr = sample[\"sampling_rate\"]\n",
        "\n",
        "    is_valid, reason = check_audio_quality(audio_array, sr)\n",
        "\n",
        "    if not is_valid:\n",
        "        removed_samples_28k.append(\n",
        "            {\"idx\": idx, \"reason\": reason, \"split\": sample[\"split\"]}\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        audio_cleaned = preprocess_audio_pipeline(audio_array, sr)\n",
        "        is_valid_after, reason_after = check_audio_quality(audio_cleaned, sr)\n",
        "\n",
        "        if is_valid_after:\n",
        "            sample[\"audio_array\"] = audio_cleaned\n",
        "            sample[\"duration\"] = len(audio_cleaned) / sr\n",
        "            cleaned_data_28k.append(sample)\n",
        "        else:\n",
        "            removed_samples_28k.append(\n",
        "                {\n",
        "                    \"idx\": idx,\n",
        "                    \"reason\": f\"After processing: {reason_after}\",\n",
        "                    \"split\": sample[\"split\"],\n",
        "                }\n",
        "            )\n",
        "    except Exception as e:\n",
        "        removed_samples_28k.append(\n",
        "            {\n",
        "                \"idx\": idx,\n",
        "                \"reason\": f\"Processing error: {str(e)}\",\n",
        "                \"split\": sample[\"split\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(f\"\\nĐã làm sạch {len(cleaned_data_28k)} samples\")\n",
        "print(f\"Đã loại bỏ {len(removed_samples_28k)} samples\")\n",
        "\n",
        "# ==========================\n",
        "# 3. TÁCH TRAIN/TEST VÀ AUGMENT CHỈ TRÊN TRAIN\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"3. TÁCH TRAIN/TEST VÀ TĂNG CƯỜNG DỮ LIỆU CHO TRAIN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cleaned_train = [s for s in cleaned_data_28k if s[\"split\"] != \"test\"]\n",
        "cleaned_test = [s for s in cleaned_data_28k if s[\"split\"] == \"test\"]\n",
        "\n",
        "print(f\"Số mẫu train (sau làm sạch): {len(cleaned_train)}\")\n",
        "print(f\"Số mẫu test  (sau làm sạch): {len(cleaned_test)}\")\n",
        "\n",
        "\n",
        "class AudioAugmentationASR:\n",
        "    @staticmethod\n",
        "    def time_stretch(audio, sr, rate_range=(0.9, 1.1)):\n",
        "        rate = random.uniform(*rate_range)\n",
        "        return effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "    @staticmethod\n",
        "    def pitch_shift(audio, sr, n_steps_range=(-1, 1)):\n",
        "        n_steps = random.randint(*n_steps_range)\n",
        "        return effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    @staticmethod\n",
        "    def add_gaussian_noise(audio, snr_db_range=(15, 30)):\n",
        "        snr_db = random.uniform(*snr_db_range)\n",
        "        signal_power = np.mean(audio**2)\n",
        "        noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "        noise = np.random.normal(0, np.sqrt(noise_power), len(audio))\n",
        "        return audio + noise\n",
        "\n",
        "    @staticmethod\n",
        "    def volume_scale(audio, scale_range=(0.8, 1.2)):\n",
        "        scale = random.uniform(*scale_range)\n",
        "        return audio * scale\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_all(audio, sr, prob=0.5):\n",
        "        augmented = audio.copy()\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentationASR.time_stretch(augmented, sr)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentationASR.pitch_shift(augmented, sr)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentationASR.add_gaussian_noise(augmented)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentationASR.volume_scale(augmented)\n",
        "\n",
        "        max_val = np.abs(augmented).max()\n",
        "        if max_val > 0:\n",
        "            augmented = augmented / max_val * 0.95\n",
        "\n",
        "        return augmented\n",
        "\n",
        "\n",
        "def augment_train_dataset(train_list, augmentation_factor=1.0):\n",
        "    \"\"\"Tăng cường dữ liệu cho train (factor=1.0 nghĩa là tạo thêm ~100% số mẫu thiểu số).\"\"\"\n",
        "    if augmentation_factor <= 0:\n",
        "        return train_list\n",
        "\n",
        "    augmented = list(train_list)\n",
        "\n",
        "    target_extra = int(len(train_list) * augmentation_factor)\n",
        "    print(f\"Sẽ tạo thêm khoảng {target_extra} mẫu augment cho train.\")\n",
        "\n",
        "    for _ in tqdm(range(target_extra), desc=\"Augmenting train\"):\n",
        "        sample = random.choice(train_list)\n",
        "        audio_array = sample[\"audio_array\"]\n",
        "        sr = sample[\"sampling_rate\"]\n",
        "\n",
        "        aug_audio = AudioAugmentationASR.apply_all(audio_array, sr)\n",
        "        new_sample = sample.copy()\n",
        "        new_sample[\"audio_array\"] = aug_audio\n",
        "        new_sample[\"duration\"] = len(aug_audio) / sr\n",
        "        new_sample[\"is_augmented\"] = True\n",
        "        augmented.append(new_sample)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "\n",
        "augmented_train = augment_train_dataset(cleaned_train, augmentation_factor=0.5)\n",
        "print(f\"\\nTrain trước augment: {len(cleaned_train)}\")\n",
        "print(f\"Train sau augment:   {len(augmented_train)}\")\n",
        "\n",
        "# ==========================\n",
        "# 4. CHIA TRAIN/VAL VÀ LƯU HF DATASET\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"4. CHIA TRAIN/VAL VÀ LƯU DỮ LIỆU CHO ASR\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_df = pd.DataFrame(augmented_train)\n",
        "\n",
        "train_split_df, val_split_df = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(f\"Số mẫu train: {len(train_split_df)}\")\n",
        "print(f\"Số mẫu val:   {len(val_split_df)}\")\n",
        "print(f\"Số mẫu test:  {len(cleaned_test)}\")\n",
        "\n",
        "\n",
        "def records_to_asr_dataset(records):\n",
        "    audio_arrays = [r[\"audio_array\"] for r in records]\n",
        "    transcripts = [r[\"transcript\"] for r in records]\n",
        "    durations = [r[\"duration\"] for r in records]\n",
        "\n",
        "    ds = Dataset.from_dict(\n",
        "        {\n",
        "            \"audio\": audio_arrays,\n",
        "            \"transcript\": transcripts,\n",
        "            \"duration\": durations,\n",
        "        }\n",
        "    )\n",
        "    ds = ds.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = records_to_asr_dataset(train_split_df.to_dict(\"records\"))\n",
        "val_ds = records_to_asr_dataset(val_split_df.to_dict(\"records\"))\n",
        "test_ds = records_to_asr_dataset(cleaned_test)\n",
        "\n",
        "OUTPUT_DIR = Path(\"./data/asr_28k\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_ds.save_to_disk(str(OUTPUT_DIR / \"train\"))\n",
        "val_ds.save_to_disk(str(OUTPUT_DIR / \"val\"))\n",
        "test_ds.save_to_disk(str(OUTPUT_DIR / \"test\"))\n",
        "\n",
        "print(\"\\nĐã lưu dữ liệu ASR đã tiền xử lý đầy đủ vào ./data/asr_28k\")\n",
        "\n",
        "# ==========================\n",
        "# 5. THỐNG KÊ\n",
        "# ==========================\n",
        "\n",
        "train_durations = [ex[\"duration\"] for ex in train_ds]\n",
        "\n",
        "stats = {\n",
        "    \"train_samples\": len(train_ds),\n",
        "    \"val_samples\": len(val_ds),\n",
        "    \"test_samples\": len(test_ds),\n",
        "    \"total_samples\": len(train_ds) + len(val_ds) + len(test_ds),\n",
        "    \"avg_duration\": float(sum(train_durations) / len(train_durations)),\n",
        "    \"min_duration\": float(min(train_durations)),\n",
        "    \"max_duration\": float(max(train_durations)),\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nThống kê chính:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
