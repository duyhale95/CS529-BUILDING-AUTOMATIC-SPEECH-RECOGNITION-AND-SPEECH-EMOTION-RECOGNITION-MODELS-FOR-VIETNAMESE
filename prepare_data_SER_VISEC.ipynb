{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chuẩn bị dữ liệu SER với bộ ViSEC\n",
        "\n",
        "Notebook này thực hiện các bước tiền xử lý cho bài toán Nhận diện cảm xúc trong giọng nói (SER) sử dụng bộ dữ liệu `hustep-lab/ViSEC`:\n",
        "\n",
        "1. Tải bộ dữ liệu ViSEC từ Hugging Face.\n",
        "2. Chuẩn hóa nhãn cảm xúc từ 4 lớp gốc (`happy`, `neutral`, `sad`, `angry`) về 3 lớp:\n",
        "   - `positive`: happy\n",
        "   - `neutral`: neutral\n",
        "   - `negative`: sad, angry\n",
        "3. Phân tích phân bố nhãn cảm xúc, accent, giới tính.\n",
        "4. Chia dữ liệu thành 3 tập:\n",
        "   - `train`: 70%\n",
        "   - `validation`: 15%\n",
        "   - `test`: 15%\n",
        "   với ràng buộc stratify theo nhãn cảm xúc.\n",
        "5. Chuẩn hóa cột `audio` về dạng `Audio(sampling_rate=16000)`.\n",
        "6. Lưu lại các tập dữ liệu dưới dạng Hugging Face Dataset bằng `save_to_disk` tại thư mục `./data/ser_visec`.\n",
        "7. Ghi thống kê cơ bản ra file `stats.json` để phục vụ báo cáo và huấn luyện sau này.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu đã có rồi thì có thể bỏ qua cell này\n",
        "%pip install -q datasets soundfile librosa tqdm\n",
        "\n",
        "from datasets import load_dataset, Dataset, Audio\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Thư mục lưu dataset SER đã xử lý\n",
        "OUTPUT_DIR = Path(\"./data/ser_visec\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Thư mục lưu dữ liệu:\", OUTPUT_DIR.resolve())\n",
        "\n",
        "# 1. Tải dataset ViSEC từ Hugging Face\n",
        "print(\"\\n[1/5] Đang tải dataset ViSEC từ Hugging Face...\")\n",
        "visec_raw = load_dataset(\"hustep-lab/ViSEC\")\n",
        "print(\"Các splits có sẵn:\", list(visec_raw.keys()))\n",
        "print(\"Số mẫu tổng (train):\", len(visec_raw[\"train\"]))\n",
        "\n",
        "# 2. Map 4 labels cảm xúc gốc → 3 labels (positive, negative, neutral)\n",
        "print(\"\\n[2/5] Đang chuẩn hóa nhãn cảm xúc từ 4 lớp về 3 lớp...\")\n",
        "\n",
        "def map_emotion_to_3_labels(emotion: str) -> str:\n",
        "    \"\"\"Map 4 nhãn ViSEC (happy, neutral, sad, angry) → 3 nhãn (positive, negative, neutral).\"\"\"\n",
        "    emotion = str(emotion).lower().strip()\n",
        "    if emotion == \"happy\":\n",
        "        return \"positive\"\n",
        "    if emotion == \"neutral\":\n",
        "        return \"neutral\"\n",
        "    if emotion in [\"sad\", \"angry\"]:\n",
        "        return \"negative\"\n",
        "    return \"neutral\"\n",
        "\n",
        "visec_data = []\n",
        "for ex in visec_raw[\"train\"]:\n",
        "    mapped_emotion = map_emotion_to_3_labels(ex[\"emotion\"])\n",
        "    visec_data.append(\n",
        "        {\n",
        "            \"audio\": ex[\"audio\"],\n",
        "            \"emotion\": mapped_emotion,\n",
        "            \"emotion_original\": ex[\"emotion\"],\n",
        "            \"duration\": float(ex[\"duration\"]),\n",
        "            \"accent\": ex[\"accent\"],\n",
        "            \"gender\": ex[\"gender\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "visec_df = pd.DataFrame(visec_data)\n",
        "\n",
        "print(\"Phân bố nhãn cảm xúc sau khi map:\")\n",
        "print(visec_df[\"emotion\"].value_counts())\n",
        "\n",
        "print(\"\\nPhân bố accent:\")\n",
        "print(visec_df[\"accent\"].value_counts())\n",
        "\n",
        "print(\"\\nPhân bố gender:\")\n",
        "print(visec_df[\"gender\"].value_counts())\n",
        "\n",
        "# 3. Chia train / validation / test với stratify theo nhãn cảm xúc\n",
        "print(\"\\n[3/5] Đang chia train / validation / test (70% / 15% / 15%) với stratify theo emotion...\")\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    visec_df,\n",
        "    test_size=0.3,\n",
        "    stratify=visec_df[\"emotion\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"emotion\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Số mẫu:\")\n",
        "print(\"  Train:\", len(train_df))\n",
        "print(\"  Val:  \", len(val_df))\n",
        "print(\"  Test: \", len(test_df))\n",
        "\n",
        "print(\"\\nPhân bố emotion trong từng split:\")\n",
        "print(\"Train:\")\n",
        "print(train_df[\"emotion\"].value_counts())\n",
        "print(\"\\nVal:\")\n",
        "print(val_df[\"emotion\"].value_counts())\n",
        "print(\"\\nTest:\")\n",
        "print(test_df[\"emotion\"].value_counts())\n",
        "\n",
        "# 4. Chuyển về Hugging Face Dataset và cast cột audio về Audio(16000)\n",
        "print(\"\\n[4/5] Đang chuyển về Hugging Face Dataset và chuẩn hóa cột audio...\")\n",
        "\n",
        "# Hàm helper để giữ lại đúng các cột cần thiết\n",
        "COLUMNS = [\"audio\", \"emotion\", \"emotion_original\", \"duration\", \"accent\", \"gender\"]\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "val_ds = Dataset.from_pandas(val_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "test_ds = Dataset.from_pandas(test_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"Ví dụ 1 mẫu train:\")\n",
        "print({k: train_ds[0][k] for k in [\"emotion\", \"emotion_original\", \"duration\", \"accent\", \"gender\"]})\n",
        "\n",
        "# 5. Lưu các split xuống đĩa và ghi thống kê\n",
        "print(\"\\n[5/5] Đang lưu các split đã xử lý và ghi thống kê...\")\n",
        "\n",
        "train_path = OUTPUT_DIR / \"train\"\n",
        "val_path = OUTPUT_DIR / \"val\"\n",
        "test_path = OUTPUT_DIR / \"test\"\n",
        "\n",
        "train_ds.save_to_disk(str(train_path))\n",
        "val_ds.save_to_disk(str(val_path))\n",
        "test_ds.save_to_disk(str(test_path))\n",
        "\n",
        "print(\"Đã lưu:\")\n",
        "print(\"  - Train:\", train_path.resolve())\n",
        "print(\"  - Val:  \", val_path.resolve())\n",
        "print(\"  - Test: \", test_path.resolve())\n",
        "\n",
        "train_durations = [ex[\"duration\"] for ex in train_ds]\n",
        "\n",
        "stats = {\n",
        "    \"train_samples\": len(train_ds),\n",
        "    \"val_samples\": len(val_ds),\n",
        "    \"test_samples\": len(test_ds),\n",
        "    \"total_samples\": len(train_ds) + len(val_ds) + len(test_ds),\n",
        "    \"emotion_distribution\": visec_df[\"emotion\"].value_counts().to_dict(),\n",
        "    \"avg_duration\": float(sum(train_durations) / len(train_durations)),\n",
        "    \"min_duration\": float(min(train_durations)),\n",
        "    \"max_duration\": float(max(train_durations)),\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nHoàn thành chuẩn bị dữ liệu SER cho bộ ViSEC.\")\n",
        "print(\"Thống kê chính:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
