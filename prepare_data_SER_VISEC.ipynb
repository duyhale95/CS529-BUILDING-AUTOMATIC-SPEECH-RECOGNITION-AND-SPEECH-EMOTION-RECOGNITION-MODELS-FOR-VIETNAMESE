{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chuẩn bị dữ liệu SER với bộ ViSEC\n",
        "\n",
        "Notebook này thực hiện các bước tiền xử lý cho bài toán Nhận diện cảm xúc trong giọng nói (SER) sử dụng bộ dữ liệu `hustep-lab/ViSEC`:\n",
        "\n",
        "1. Tải bộ dữ liệu ViSEC từ Hugging Face.\n",
        "2. Chuẩn hóa nhãn cảm xúc từ 4 lớp gốc (`happy`, `neutral`, `sad`, `angry`) về 3 lớp:\n",
        "   - `positive`: happy\n",
        "   - `neutral`: neutral\n",
        "   - `negative`: sad, angry\n",
        "3. Phân tích phân bố nhãn cảm xúc, accent, giới tính.\n",
        "4. Chia dữ liệu thành 3 tập:\n",
        "   - `train`: 70%\n",
        "   - `validation`: 15%\n",
        "   - `test`: 15%\n",
        "   với ràng buộc stratify theo nhãn cảm xúc.\n",
        "5. Chuẩn hóa cột `audio` về dạng `Audio(sampling_rate=16000)`.\n",
        "6. Lưu lại các tập dữ liệu dưới dạng Hugging Face Dataset bằng `save_to_disk` tại thư mục `./data/ser_visec`.\n",
        "7. Ghi thống kê cơ bản ra file `stats.json` để phục vụ báo cáo và huấn luyện sau này.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\haled\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thư mục lưu dữ liệu: D:\\Downloads\\CS529_ASR_SER\\data\\ser_visec\n",
            "\n",
            "[1/5] Đang tải dataset ViSEC từ Hugging Face...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\haled\\.cache\\huggingface\\hub\\datasets--hustep-lab--ViSEC. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Generating train split: 100%|██████████| 5280/5280 [00:04<00:00, 1189.26 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Các splits có sẵn: ['train']\n",
            "Số mẫu tổng (train): 5280\n",
            "\n",
            "[2/5] Đang chuẩn hóa nhãn cảm xúc từ 4 lớp về 3 lớp...\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "To support decoding audio data, please install 'torchcodec'.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m visec_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m visec_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     39\u001b[0m     mapped_emotion \u001b[38;5;241m=\u001b[39m map_emotion_to_3_labels(ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     40\u001b[0m     visec_data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     41\u001b[0m         {\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m         }\n\u001b[0;32m     49\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:2483\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pa_subtable\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[0;32m   2482\u001b[0m             pa_subtable_ex \u001b[38;5;241m=\u001b[39m pa_subtable\u001b[38;5;241m.\u001b[39mslice(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 2483\u001b[0m             formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2484\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpa_subtable_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2485\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2486\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2487\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2488\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2489\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2490\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m formatted_output\n\u001b[0;32m   2491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py:2105\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m   2106\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[0;32m   2107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2108\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2109\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2110\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2111\u001b[0m         )\n\u001b[0;32m   2112\u001b[0m     }\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py:2106\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2106\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2108\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2109\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2110\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2111\u001b[0m         )\n\u001b[0;32m   2112\u001b[0m     }\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py:1414\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
            "File \u001b[1;32mc:\\Users\\haled\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\audio.py:186\u001b[0m, in \u001b[0;36mAudio.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo support decoding audio data, please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorchcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoding is disabled for this feature. Please use Audio(decode=True) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: To support decoding audio data, please install 'torchcodec'."
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện cần thiết (chạy một lần trong môi trường mới)\n",
        "# Nếu đã có rồi thì có thể bỏ qua cell này\n",
        "%pip install -q datasets soundfile librosa tqdm torchcodec\n",
        "\n",
        "from datasets import load_dataset, Dataset, Audio\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Thư mục lưu dataset SER đã xử lý\n",
        "OUTPUT_DIR = Path(\"./data/ser_visec\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Thư mục lưu dữ liệu:\", OUTPUT_DIR.resolve())\n",
        "\n",
        "# 1. Tải dataset ViSEC từ Hugging Face\n",
        "print(\"\\n[1/5] Đang tải dataset ViSEC từ Hugging Face...\")\n",
        "visec_raw = load_dataset(\"hustep-lab/ViSEC\")\n",
        "print(\"Các splits có sẵn:\", list(visec_raw.keys()))\n",
        "print(\"Số mẫu tổng (train):\", len(visec_raw[\"train\"]))\n",
        "\n",
        "# 2. Map 4 labels cảm xúc gốc → 3 labels (positive, negative, neutral)\n",
        "print(\"\\n[2/5] Đang chuẩn hóa nhãn cảm xúc từ 4 lớp về 3 lớp...\")\n",
        "\n",
        "def map_emotion_to_3_labels(emotion: str) -> str:\n",
        "    \"\"\"Map 4 nhãn ViSEC (happy, neutral, sad, angry) → 3 nhãn (positive, negative, neutral).\"\"\"\n",
        "    emotion = str(emotion).lower().strip()\n",
        "    if emotion == \"happy\":\n",
        "        return \"positive\"\n",
        "    if emotion == \"neutral\":\n",
        "        return \"neutral\"\n",
        "    if emotion in [\"sad\", \"angry\"]:\n",
        "        return \"negative\"\n",
        "    return \"neutral\"\n",
        "\n",
        "visec_data = []\n",
        "for ex in visec_raw[\"train\"]:\n",
        "    mapped_emotion = map_emotion_to_3_labels(ex[\"emotion\"])\n",
        "    visec_data.append(\n",
        "        {\n",
        "            \"audio\": ex[\"audio\"],\n",
        "            \"emotion\": mapped_emotion,\n",
        "            \"emotion_original\": ex[\"emotion\"],\n",
        "            \"duration\": float(ex[\"duration\"]),\n",
        "            \"accent\": ex[\"accent\"],\n",
        "            \"gender\": ex[\"gender\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "visec_df = pd.DataFrame(visec_data)\n",
        "\n",
        "print(\"Phân bố nhãn cảm xúc sau khi map:\")\n",
        "print(visec_df[\"emotion\"].value_counts())\n",
        "\n",
        "print(\"\\nPhân bố accent:\")\n",
        "print(visec_df[\"accent\"].value_counts())\n",
        "\n",
        "print(\"\\nPhân bố gender:\")\n",
        "print(visec_df[\"gender\"].value_counts())\n",
        "\n",
        "# 3. Chia train / validation / test với stratify theo nhãn cảm xúc\n",
        "print(\"\\n[3/5] Đang chia train / validation / test (70% / 15% / 15%) với stratify theo emotion...\")\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    visec_df,\n",
        "    test_size=0.3,\n",
        "    stratify=visec_df[\"emotion\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"emotion\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Số mẫu:\")\n",
        "print(\"  Train:\", len(train_df))\n",
        "print(\"  Val:  \", len(val_df))\n",
        "print(\"  Test: \", len(test_df))\n",
        "\n",
        "print(\"\\nPhân bố emotion trong từng split:\")\n",
        "print(\"Train:\")\n",
        "print(train_df[\"emotion\"].value_counts())\n",
        "print(\"\\nVal:\")\n",
        "print(val_df[\"emotion\"].value_counts())\n",
        "print(\"\\nTest:\")\n",
        "print(test_df[\"emotion\"].value_counts())\n",
        "\n",
        "# 4. Chuyển về Hugging Face Dataset và cast cột audio về Audio(16000)\n",
        "print(\"\\n[4/5] Đang chuyển về Hugging Face Dataset và chuẩn hóa cột audio...\")\n",
        "\n",
        "# Hàm helper để giữ lại đúng các cột cần thiết\n",
        "COLUMNS = [\"audio\", \"emotion\", \"emotion_original\", \"duration\", \"accent\", \"gender\"]\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "val_ds = Dataset.from_pandas(val_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "test_ds = Dataset.from_pandas(test_df[COLUMNS]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"Ví dụ 1 mẫu train:\")\n",
        "print({k: train_ds[0][k] for k in [\"emotion\", \"emotion_original\", \"duration\", \"accent\", \"gender\"]})\n",
        "\n",
        "# 5. Lưu các split xuống đĩa và ghi thống kê\n",
        "print(\"\\n[5/5] Đang lưu các split đã xử lý và ghi thống kê...\")\n",
        "\n",
        "train_path = OUTPUT_DIR / \"train\"\n",
        "val_path = OUTPUT_DIR / \"val\"\n",
        "test_path = OUTPUT_DIR / \"test\"\n",
        "\n",
        "train_ds.save_to_disk(str(train_path))\n",
        "val_ds.save_to_disk(str(val_path))\n",
        "test_ds.save_to_disk(str(test_path))\n",
        "\n",
        "print(\"Đã lưu:\")\n",
        "print(\"  - Train:\", train_path.resolve())\n",
        "print(\"  - Val:  \", val_path.resolve())\n",
        "print(\"  - Test: \", test_path.resolve())\n",
        "\n",
        "train_durations = [ex[\"duration\"] for ex in train_ds]\n",
        "\n",
        "stats = {\n",
        "    \"train_samples\": len(train_ds),\n",
        "    \"val_samples\": len(val_ds),\n",
        "    \"test_samples\": len(test_ds),\n",
        "    \"total_samples\": len(train_ds) + len(val_ds) + len(test_ds),\n",
        "    \"emotion_distribution\": visec_df[\"emotion\"].value_counts().to_dict(),\n",
        "    \"avg_duration\": float(sum(train_durations) / len(train_durations)),\n",
        "    \"min_duration\": float(min(train_durations)),\n",
        "    \"max_duration\": float(max(train_durations)),\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nHoàn thành chuẩn bị dữ liệu SER cho bộ ViSEC.\")\n",
        "print(\"Thống kê chính:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phiên bản đầy đủ tiền xử lý SER (ViSEC) theo 6 bước\n",
        "\n",
        "Phần dưới đây hiện thực đầy đủ pipeline tiền xử lý cho SER trên bộ `hustep-lab/ViSEC` đúng theo Nội dung 2 trong thuyết minh:\n",
        "\n",
        "1. **Chuẩn hóa định dạng**: audio về 16 kHz, mono, chuẩn hóa biên độ (tránh clipping).\n",
        "2. **Lọc nhiễu, cắt im lặng, loại bỏ mẫu lỗi**: loại bỏ mẫu quá ngắn/dài, quá nhiều im lặng, clipping, RMS quá thấp.\n",
        "3. **Cân bằng dữ liệu giữa các nhãn cảm xúc**: dùng chiến lược `undersample` (hoặc `oversample`).\n",
        "4. **Tăng cường dữ liệu (data augmentation)**: time-stretch, pitch-shift, thêm noise, thay đổi volume.\n",
        "5. **Chia dữ liệu**: `train` / `val` / `test` với stratify theo nhãn cảm xúc.\n",
        "6. **Lưu kết quả**: lưu thành Hugging Face Dataset tại `./data/ser_visec/{train,val,test}` và ghi thống kê `stats.json`.\n",
        "\n",
        "Sau khi chạy xong cell code bên dưới, bạn có thể sử dụng trực tiếp các thư mục này trong notebook `finetune_SER_VISEC.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PIPELINE TIỀN XỬ LÝ ĐẦY ĐỦ CHO SER (VISEC)\n",
        "\n",
        "%pip install -q datasets librosa soundfile tqdm noisereduce scikit-learn torchcodec\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "\n",
        "from scipy import signal\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from datasets import load_dataset, Dataset, Audio\n",
        "import json\n",
        "import random\n",
        "import librosa.effects as effects\n",
        "\n",
        "# ==========================\n",
        "# 1. CHUẨN HÓA + TẠO normalized_data\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"1. CHUẨN HÓA ĐỊNH DẠNG VÀ TẠO NORMALIZED_DATA CHO VISEC\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "visec_raw = load_dataset(\"hustep-lab/ViSEC\")\n",
        "print(\"Splits:\", list(visec_raw.keys()))\n",
        "print(\"Số mẫu (train):\", len(visec_raw[\"train\"]))\n",
        "\n",
        "\n",
        "def map_emotion_to_3_labels(emotion: str) -> str:\n",
        "    emotion = str(emotion).lower().strip()\n",
        "    if emotion == \"happy\":\n",
        "        return \"positive\"\n",
        "    if emotion == \"neutral\":\n",
        "        return \"neutral\"\n",
        "    if emotion in [\"sad\", \"angry\"]:\n",
        "        return \"negative\"\n",
        "    return \"neutral\"\n",
        "\n",
        "\n",
        "normalized_data = []\n",
        "\n",
        "target_sr = 16000\n",
        "\n",
        "for idx, ex in enumerate(tqdm(visec_raw[\"train\"], desc=\"Normalizing ViSEC\")):\n",
        "    audio = ex[\"audio\"]  # {'array', 'sampling_rate'}\n",
        "    y = audio[\"array\"]\n",
        "    sr = audio[\"sampling_rate\"]\n",
        "\n",
        "    # Đảm bảo mono\n",
        "    if y.ndim > 1:\n",
        "        y = librosa.to_mono(y)\n",
        "\n",
        "    # Resample về 16 kHz nếu cần\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "\n",
        "    # Normalize amplitude (tránh clipping)\n",
        "    max_val = np.abs(y).max()\n",
        "    if max_val > 0.95:\n",
        "        y = y / max_val * 0.95\n",
        "\n",
        "    normalized_data.append(\n",
        "        {\n",
        "            \"audio_array\": y,\n",
        "            \"sampling_rate\": sr,\n",
        "            \"emotion\": map_emotion_to_3_labels(ex[\"emotion\"]),\n",
        "            \"emotion_original\": ex[\"emotion\"],\n",
        "            \"duration\": len(y) / sr,\n",
        "            \"accent\": ex[\"accent\"],\n",
        "            \"gender\": ex[\"gender\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f\"\\nĐã chuẩn hóa {len(normalized_data)} samples từ ViSEC.\")\n",
        "\n",
        "# ==========================\n",
        "# 2. LỌC NHIỄU, CẮT IM LẶNG, LOẠI MẪU LỖI\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"2. LỌC NHIỄU, CẮT IM LẶNG, LOẠI MẪU LỖI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def detect_silence(audio, sr, threshold_db=-40):\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    rms_db = librosa.power_to_db(rms**2)\n",
        "    silence_mask = rms_db < threshold_db\n",
        "    silence_ratio = np.sum(silence_mask) / len(silence_mask)\n",
        "    return silence_ratio\n",
        "\n",
        "\n",
        "def remove_silence(audio, sr, frame_length=2048, hop_length=512, top_db=20):\n",
        "    audio_trimmed, _ = librosa.effects.trim(\n",
        "        audio,\n",
        "        top_db=top_db,\n",
        "        frame_length=frame_length,\n",
        "        hop_length=hop_length,\n",
        "    )\n",
        "    return audio_trimmed\n",
        "\n",
        "\n",
        "def reduce_noise(audio, sr, stationary=False):\n",
        "    try:\n",
        "        audio_clean = nr.reduce_noise(\n",
        "            y=audio,\n",
        "            sr=sr,\n",
        "            stationary=stationary,\n",
        "        )\n",
        "        return audio_clean\n",
        "    except Exception:\n",
        "        # fallback: high-pass filter\n",
        "        b, a = signal.butter(3, 80, \"hp\", fs=sr)\n",
        "        audio_clean = signal.filtfilt(b, a, audio)\n",
        "        return audio_clean\n",
        "\n",
        "\n",
        "def check_audio_quality(audio, sr, min_duration=0.5, max_duration=30):\n",
        "    duration = len(audio) / sr\n",
        "\n",
        "    # 1. Độ dài\n",
        "    if duration < min_duration or duration > max_duration:\n",
        "        return False, f\"Invalid duration: {duration:.2f}s\"\n",
        "\n",
        "    # 2. Tỷ lệ im lặng\n",
        "    silence_ratio = detect_silence(audio, sr)\n",
        "    if silence_ratio > 0.8:\n",
        "        return False, f\"Too much silence: {silence_ratio:.2%}\"\n",
        "\n",
        "    # 3. Clipping\n",
        "    max_val = np.abs(audio).max()\n",
        "    if max_val > 0.99:\n",
        "        return False, f\"Audio clipping detected: {max_val:.3f}\"\n",
        "\n",
        "    # 4. RMS energy\n",
        "    rms = librosa.feature.rms(y=audio)[0].mean()\n",
        "    if rms < 0.01:\n",
        "        return False, f\"RMS too low: {rms:.4f}\"\n",
        "\n",
        "    return True, \"OK\"\n",
        "\n",
        "\n",
        "def preprocess_audio_pipeline(audio_array, sr, reduce_noise_flag=True):\n",
        "    # 1. Remove silence\n",
        "    audio_processed = remove_silence(audio_array, sr)\n",
        "\n",
        "    # 2. Reduce noise (optional)\n",
        "    if reduce_noise_flag:\n",
        "        audio_processed = reduce_noise(audio_processed, sr)\n",
        "\n",
        "    # 3. Normalize\n",
        "    max_val = np.abs(audio_processed).max()\n",
        "    if max_val > 0:\n",
        "        audio_processed = audio_processed / max_val * 0.95\n",
        "\n",
        "    return audio_processed\n",
        "\n",
        "\n",
        "cleaned_data = []\n",
        "removed_samples = []\n",
        "\n",
        "for idx, sample in enumerate(tqdm(normalized_data, desc=\"Cleaning audio\")):\n",
        "    audio_array = sample[\"audio_array\"]\n",
        "    sr = sample[\"sampling_rate\"]\n",
        "\n",
        "    is_valid, reason = check_audio_quality(audio_array, sr)\n",
        "\n",
        "    if not is_valid:\n",
        "        removed_samples.append(\n",
        "            {\n",
        "                \"idx\": idx,\n",
        "                \"reason\": reason,\n",
        "                \"emotion\": sample[\"emotion\"],\n",
        "            }\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        audio_cleaned = preprocess_audio_pipeline(audio_array, sr)\n",
        "        is_valid_after, reason_after = check_audio_quality(audio_cleaned, sr)\n",
        "\n",
        "        if is_valid_after:\n",
        "            sample[\"audio_array\"] = audio_cleaned\n",
        "            sample[\"duration\"] = len(audio_cleaned) / sr\n",
        "            cleaned_data.append(sample)\n",
        "        else:\n",
        "            removed_samples.append(\n",
        "                {\n",
        "                    \"idx\": idx,\n",
        "                    \"reason\": f\"After processing: {reason_after}\",\n",
        "                    \"emotion\": sample[\"emotion\"],\n",
        "                }\n",
        "            )\n",
        "    except Exception as e:\n",
        "        removed_samples.append(\n",
        "            {\n",
        "                \"idx\": idx,\n",
        "                \"reason\": f\"Processing error: {str(e)}\",\n",
        "                \"emotion\": sample[\"emotion\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(f\"\\nĐã làm sạch {len(cleaned_data)} samples\")\n",
        "print(f\"Đã loại bỏ {len(removed_samples)} samples\")\n",
        "\n",
        "if removed_samples:\n",
        "    print(\"\\nMột số lý do loại bỏ phổ biến:\")\n",
        "    reason_counts = pd.Series([r[\"reason\"] for r in removed_samples]).value_counts()\n",
        "    print(reason_counts.head(10))\n",
        "\n",
        "# ==========================\n",
        "# 3. CÂN BẰNG DỮ LIỆU GIỮA CÁC NHÃN CẢM XÚC\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"3. CÂN BẰNG DỮ LIỆU GIỮA CÁC NHÃN CẢM XÚC\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def balance_emotion_labels(data_list, target_count=None, strategy=\"undersample\"):\n",
        "    df = pd.DataFrame(data_list)\n",
        "    emotion_counts = df[\"emotion\"].value_counts()\n",
        "    print(\"Phân bố ban đầu:\")\n",
        "    print(emotion_counts)\n",
        "\n",
        "    if target_count is None:\n",
        "        target_count = emotion_counts.min()\n",
        "\n",
        "    balanced_data = []\n",
        "\n",
        "    for emotion in emotion_counts.index:\n",
        "        emotion_data = df[df[\"emotion\"] == emotion].to_dict(\"records\")\n",
        "\n",
        "        if len(emotion_data) > target_count:\n",
        "            if strategy == \"undersample\":\n",
        "                emotion_data = resample(\n",
        "                    emotion_data,\n",
        "                    n_samples=target_count,\n",
        "                    random_state=42,\n",
        "                    replace=False,\n",
        "                )\n",
        "        elif len(emotion_data) < target_count:\n",
        "            if strategy == \"oversample\":\n",
        "                emotion_data = resample(\n",
        "                    emotion_data,\n",
        "                    n_samples=target_count,\n",
        "                    random_state=42,\n",
        "                    replace=True,\n",
        "                )\n",
        "\n",
        "        balanced_data.extend(emotion_data)\n",
        "\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(balanced_data)\n",
        "\n",
        "    balanced_df = pd.DataFrame(balanced_data)\n",
        "    print(\"\\nPhân bố sau khi cân bằng:\")\n",
        "    print(balanced_df[\"emotion\"].value_counts())\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "\n",
        "balanced_data = balance_emotion_labels(cleaned_data, strategy=\"undersample\")\n",
        "\n",
        "# ==========================\n",
        "# 4. DATA AUGMENTATION\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"4. TĂNG CƯỜNG DỮ LIỆU (DATA AUGMENTATION)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "class AudioAugmentation:\n",
        "    @staticmethod\n",
        "    def time_stretch(audio, sr, rate_range=(0.8, 1.2)):\n",
        "        rate = random.uniform(*rate_range)\n",
        "        return effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "    @staticmethod\n",
        "    def pitch_shift(audio, sr, n_steps_range=(-2, 2)):\n",
        "        n_steps = random.randint(*n_steps_range)\n",
        "        return effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    @staticmethod\n",
        "    def add_gaussian_noise(audio, snr_db_range=(10, 30)):\n",
        "        snr_db = random.uniform(*snr_db_range)\n",
        "        signal_power = np.mean(audio**2)\n",
        "        noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "        noise = np.random.normal(0, np.sqrt(noise_power), len(audio))\n",
        "        return audio + noise\n",
        "\n",
        "    @staticmethod\n",
        "    def volume_scale(audio, scale_range=(0.7, 1.3)):\n",
        "        scale = random.uniform(*scale_range)\n",
        "        return audio * scale\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_all(audio, sr, prob=0.5):\n",
        "        augmented = audio.copy()\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentation.time_stretch(augmented, sr)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentation.pitch_shift(augmented, sr)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentation.add_gaussian_noise(augmented)\n",
        "\n",
        "        if random.random() < prob:\n",
        "            augmented = AudioAugmentation.volume_scale(augmented)\n",
        "\n",
        "        max_val = np.abs(augmented).max()\n",
        "        if max_val > 0:\n",
        "            augmented = augmented / max_val * 0.95\n",
        "\n",
        "        return augmented\n",
        "\n",
        "\n",
        "def augment_dataset(data_list, augmentation_factor=2, apply_to_minority_only=True):\n",
        "    df = pd.DataFrame(data_list)\n",
        "    emotion_counts = df[\"emotion\"].value_counts()\n",
        "    min_count = emotion_counts.min()\n",
        "    max_count = emotion_counts.max()\n",
        "\n",
        "    augmented_data = []\n",
        "\n",
        "    for emotion in emotion_counts.index:\n",
        "        emotion_data = df[df[\"emotion\"] == emotion].to_dict(\"records\")\n",
        "        augmented_data.extend(emotion_data)\n",
        "\n",
        "        should_augment = True\n",
        "        if apply_to_minority_only:\n",
        "            should_augment = len(emotion_data) < max_count\n",
        "\n",
        "        if should_augment:\n",
        "            target_count = int(min_count * augmentation_factor)\n",
        "            num_to_augment = target_count - len(emotion_data)\n",
        "\n",
        "            if num_to_augment > 0:\n",
        "                print(f\"\\nAugmenting {emotion}: {len(emotion_data)} → {target_count}\")\n",
        "                for _ in range(num_to_augment):\n",
        "                    sample = random.choice(emotion_data)\n",
        "                    audio_array = sample[\"audio_array\"]\n",
        "                    sr = sample[\"sampling_rate\"]\n",
        "\n",
        "                    aug_audio = AudioAugmentation.apply_all(audio_array, sr)\n",
        "\n",
        "                    new_sample = sample.copy()\n",
        "                    new_sample[\"audio_array\"] = aug_audio\n",
        "                    new_sample[\"duration\"] = len(aug_audio) / sr\n",
        "                    new_sample[\"is_augmented\"] = True\n",
        "                    augmented_data.append(new_sample)\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "\n",
        "augmented_data = augment_dataset(\n",
        "    balanced_data,\n",
        "    augmentation_factor=2,\n",
        "    apply_to_minority_only=True,\n",
        ")\n",
        "\n",
        "print(f\"\\nĐã tăng cường: {len(balanced_data)} → {len(augmented_data)} samples\")\n",
        "\n",
        "# ==========================\n",
        "# 5. CHIA TRAIN/VAL/TEST VÀ LƯU DATASET\n",
        "# ==========================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"5. CHIA TRAIN/VAL/TEST VÀ LƯU DATASET CHO SER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def split_dataset(\n",
        "    data_list,\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    test_ratio=0.15,\n",
        "    stratify_column=\"emotion\",\n",
        "    random_state=42,\n",
        "):\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
        "\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df,\n",
        "        test_size=(val_ratio + test_ratio),\n",
        "        stratify=df[stratify_column] if stratify_column else None,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    val_size = val_ratio / (val_ratio + test_ratio)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_size),\n",
        "        stratify=temp_df[stratify_column] if stratify_column else None,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTổng số samples: {len(df)}\")\n",
        "    print(f\"  Train: {len(train_df)}\")\n",
        "    print(f\"  Val:   {len(val_df)}\")\n",
        "    print(f\"  Test:  {len(test_df)}\")\n",
        "\n",
        "    print(\"\\nPhân bố emotion (train):\")\n",
        "    print(train_df[\"emotion\"].value_counts())\n",
        "    print(\"\\nPhân bố emotion (val):\")\n",
        "    print(val_df[\"emotion\"].value_counts())\n",
        "    print(\"\\nPhân bố emotion (test):\")\n",
        "    print(test_df[\"emotion\"].value_counts())\n",
        "\n",
        "    return {\n",
        "        \"train\": train_df.to_dict(\"records\"),\n",
        "        \"val\": val_df.to_dict(\"records\"),\n",
        "        \"test\": test_df.to_dict(\"records\"),\n",
        "    }\n",
        "\n",
        "\n",
        "splits = split_dataset(augmented_data)\n",
        "\n",
        "OUTPUT_DIR = Path(\"./data/ser_visec\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def records_to_dataset(records):\n",
        "    audio_arrays = [r[\"audio_array\"] for r in records]\n",
        "    srs = [r[\"sampling_rate\"] for r in records]\n",
        "    emotions = [r[\"emotion\"] for r in records]\n",
        "    emotions_orig = [r[\"emotion_original\"] for r in records]\n",
        "    durations = [r[\"duration\"] for r in records]\n",
        "    accents = [r[\"accent\"] for r in records]\n",
        "    genders = [r[\"gender\"] for r in records]\n",
        "\n",
        "    ds = Dataset.from_dict(\n",
        "        {\n",
        "            \"audio\": audio_arrays,\n",
        "            \"sampling_rate\": srs,\n",
        "            \"emotion\": emotions,\n",
        "            \"emotion_original\": emotions_orig,\n",
        "            \"duration\": durations,\n",
        "            \"accent\": accents,\n",
        "            \"gender\": genders,\n",
        "        }\n",
        "    )\n",
        "    # cast cột audio: dùng sampling_rate từ field \"sampling_rate\" không trực tiếp được,\n",
        "    # nhưng vì ta đã resample về 16000 nên có thể dùng Audio(16000).\n",
        "    ds = ds.remove_columns([\"sampling_rate\"]).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = records_to_dataset(splits[\"train\"])\n",
        "val_ds = records_to_dataset(splits[\"val\"])\n",
        "test_ds = records_to_dataset(splits[\"test\"])\n",
        "\n",
        "train_ds.save_to_disk(str(OUTPUT_DIR / \"train\"))\n",
        "val_ds.save_to_disk(str(OUTPUT_DIR / \"val\"))\n",
        "test_ds.save_to_disk(str(OUTPUT_DIR / \"test\"))\n",
        "\n",
        "print(\"\\nĐã lưu dữ liệu SER đã tiền xử lý đầy đủ vào ./data/ser_visec\")\n",
        "\n",
        "# Thống kê\n",
        "train_durations = [ex[\"duration\"] for ex in train_ds]\n",
        "\n",
        "stats = {\n",
        "    \"train_samples\": len(train_ds),\n",
        "    \"val_samples\": len(val_ds),\n",
        "    \"test_samples\": len(test_ds),\n",
        "    \"total_samples\": len(train_ds) + len(val_ds) + len(test_ds),\n",
        "    \"emotion_distribution_train\": pd.Series(\n",
        "        [ex[\"emotion\"] for ex in train_ds]\n",
        "    ).value_counts().to_dict(),\n",
        "    \"avg_duration\": float(sum(train_durations) / len(train_durations)),\n",
        "    \"min_duration\": float(min(train_durations)),\n",
        "    \"max_duration\": float(max(train_durations)),\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nThống kê chính:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
